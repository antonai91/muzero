{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "criminal-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tropical-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plugin_write_and_run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "discrete-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run ../src/self_play.py\n",
    "import math\n",
    "import random\n",
    "from typing import List\n",
    "import numpy\n",
    "\n",
    "from utilities import *\n",
    "from config import *\n",
    "from game import *\n",
    "from shared_storage import *\n",
    "from networks import *\n",
    "from mcts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gothic-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a ../src/self_play.py\n",
    "\n",
    "def run_selfplay(config: MuZeroConfig, storage: SharedStorage, replay_buffer: ReplayBuffer, train_episodes: int):\n",
    "    \"\"\"Take the latest network, produces multiple games and save them in the shared replay buffer\"\"\"\n",
    "    network = storage.latest_network()\n",
    "    returns = []\n",
    "    for _ in range(train_episodes):\n",
    "        game = play_game(config, network)\n",
    "        replay_buffer.save_game(game)\n",
    "        returns.append(sum(game.rewards))\n",
    "    return sum(returns) / train_episodes\n",
    "\n",
    "def run_eval(config: MuZeroConfig, storage: SharedStorage, eval_episodes: int):\n",
    "    \"\"\"Evaluate MuZero without noise added to the prior of the root and without softmax action selection\"\"\"\n",
    "    network = storage.latest_network()\n",
    "    returns = []\n",
    "    for _ in range(eval_episodes):\n",
    "        game = play_game(config, network, train=False)\n",
    "        returns.append(sum(game.rewards))\n",
    "    return sum(returns) / eval_episodes if eval_episodes else 0\n",
    "\n",
    "def play_game(config: MuZeroConfig, network: SuperNetwork, train: bool = True) -> Game:\n",
    "    \"\"\"\n",
    "    Each game is produced by starting at the initial board position, then\n",
    "    repeatedly executing a Monte Carlo Tree Search to generate moves until the end\n",
    "    of the game is reached.\n",
    "    \"\"\"\n",
    "    game = config.new_game()\n",
    "    mode_action_select = 'softmax' if train else 'max'\n",
    "\n",
    "    while not game.terminal() and len(game.history) < config.max_moves:\n",
    "        # At the root of the search tree we use the representation function to\n",
    "        # obtain a hidden state given the current observation.\n",
    "        root = Node(0)\n",
    "        current_observation = game.make_image(-1)\n",
    "        expand_node(root, game.to_play(), game.legal_actions(), network.initial_inference(current_observation))\n",
    "        if train:\n",
    "            add_exploration_noise(config, root)\n",
    "\n",
    "        # We then run a Monte Carlo Tree Search using only action sequences and the\n",
    "        # model learned by the networks.\n",
    "        run_mcts(config, root, game.action_history(), network)\n",
    "        action = select_action(config, len(game.history), root, network, mode=mode_action_select)\n",
    "        game.apply(action)\n",
    "        game.store_search_statistics(root)\n",
    "    return game"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
